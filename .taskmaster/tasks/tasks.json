{
  "master": {
    "tasks": [
      {
        "id": 26,
        "title": "Setup PostgreSQL Database Configuration",
        "description": "Configure the application to connect to PostgreSQL using environment variables and implement connection pooling for production readiness.",
        "details": "1. Add SQLAlchemy and psycopg2-binary to requirements.txt:\n```\nsqlalchemy==2.0.23\npsycopg2-binary==2.9.9\npython-dotenv==1.0.0\n```\n\n2. Create a database configuration module (db_config.py):\n```python\nimport os\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker, scoped_session\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# Get database URL from environment variable with fallback for development\nDATABASE_URL = os.getenv('DATABASE_URL', 'postgresql://postgres:postgres@localhost:5432/gmail_unsubscriber')\n\n# Create engine with connection pooling configured for production\nengine = create_engine(\n    DATABASE_URL,\n    pool_size=5,  # Reasonable default for most applications\n    max_overflow=10,  # Allow up to 10 connections beyond pool_size when needed\n    pool_timeout=30,  # Connection timeout in seconds\n    pool_recycle=1800,  # Recycle connections after 30 minutes\n    echo=False  # Set to True for SQL query logging during development\n)\n\n# Create session factory\nSessionFactory = sessionmaker(bind=engine)\n\n# Create thread-safe scoped session for handling concurrent requests\nSession = scoped_session(SessionFactory)\n\n# Base class for all models\nBase = declarative_base()\n\ndef init_db():\n    \"\"\"Initialize database, creating tables if they don't exist\"\"\"\n    Base.metadata.create_all(engine)\n\ndef get_session():\n    \"\"\"Get a database session\"\"\"\n    return Session()\n\ndef close_session(session):\n    \"\"\"Close a database session\"\"\"\n    session.close()\n```\n\n3. Update application startup code to initialize the database:\n```python\nfrom db_config import init_db\n\n# Call during application startup\ninit_db()\n```\n\n4. Create a .env.example file to document required environment variables:\n```\nDATABASE_URL=postgresql://username:password@localhost:5432/gmail_unsubscriber\n```",
        "testStrategy": "1. Unit test the database configuration module:\n   - Test connection with a test database URL\n   - Verify session creation and closing\n   - Test init_db function creates tables\n\n2. Integration test:\n   - Use a test PostgreSQL instance (can be in Docker)\n   - Verify connection pooling by simulating multiple concurrent connections\n   - Test error handling for invalid database URLs\n\n3. Environment variable test:\n   - Test fallback to default URL when environment variable is not set\n   - Test successful connection with valid environment variable",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 27,
        "title": "Create SQLAlchemy ORM Models",
        "description": "Define SQLAlchemy ORM models for User, Stats, and Activity as specified in the requirements.",
        "details": "Create a models.py file with the following SQLAlchemy models:\n\n```python\nfrom sqlalchemy import Column, String, Integer, Float, ForeignKey, DateTime, JSON, UniqueConstraint\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import relationship\nfrom datetime import datetime\nfrom db_config import Base\n\nclass User(Base):\n    __tablename__ = 'users'\n    \n    email = Column(String(255), primary_key=True)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n    \n    # Relationships\n    stats = relationship('Stats', uselist=False, back_populates='user', cascade='all, delete-orphan')\n    activities = relationship('Activity', back_populates='user', cascade='all, delete-orphan')\n    \n    def __repr__(self):\n        return f\"<User(email='{self.email}')>\"\n\nclass Stats(Base):\n    __tablename__ = 'stats'\n    \n    id = Column(Integer, primary_key=True)\n    user_email = Column(String(255), ForeignKey('users.email', ondelete='CASCADE'), unique=True, nullable=False)\n    total_scanned = Column(Integer, default=0)\n    total_unsubscribed = Column(Integer, default=0)\n    time_saved = Column(Float, default=0.0)  # in minutes\n    domains_unsubscribed = Column(JSON, default=dict)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n    \n    # Relationship\n    user = relationship('User', back_populates='stats')\n    \n    def __repr__(self):\n        return f\"<Stats(user_email='{self.user_email}', total_scanned={self.total_scanned}, total_unsubscribed={self.total_unsubscribed})>\"\n\nclass Activity(Base):\n    __tablename__ = 'activities'\n    \n    id = Column(Integer, primary_key=True)\n    user_email = Column(String(255), ForeignKey('users.email', ondelete='CASCADE'), nullable=False)\n    activity_type = Column(String(50), nullable=False)  # e.g., 'scan', 'unsubscribe'\n    timestamp = Column(DateTime, default=datetime.utcnow)\n    metadata = Column(JSON, default=dict)  # Store additional activity data as JSON\n    \n    # Relationship\n    user = relationship('User', back_populates='activities')\n    \n    def __repr__(self):\n        return f\"<Activity(user_email='{self.user_email}', activity_type='{self.activity_type}', timestamp='{self.timestamp}')>\"\n```\n\nThe models follow these design principles:\n1. User has email as primary key to uniquely identify users\n2. Stats has a one-to-one relationship with User\n3. Activity has a many-to-one relationship with User\n4. JSON fields for flexible storage of domains_unsubscribed and activity metadata\n5. Timestamps for auditing and tracking\n6. Cascade deletes to maintain referential integrity\n7. Appropriate column types and constraints",
        "testStrategy": "1. Unit tests for model definitions:\n   - Test model creation with valid data\n   - Test relationships between models\n   - Test default values\n\n2. Integration tests with test database:\n   - Create test database and initialize tables\n   - Insert test data and verify persistence\n   - Test cascade operations (e.g., deleting a user should delete associated stats and activities)\n   - Test JSON field serialization and deserialization\n\n3. Schema validation tests:\n   - Verify constraints (e.g., unique constraints, foreign keys)\n   - Test field length limits",
        "priority": "high",
        "dependencies": [
          26
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 28,
        "title": "Implement User Data Access Layer",
        "description": "Create a data access layer to handle CRUD operations for user data, ensuring proper transaction management and error handling.",
        "details": "Create a user_repository.py file with the following implementation:\n\n```python\nfrom sqlalchemy.exc import SQLAlchemyError\nfrom models import User, Stats\nfrom db_config import get_session, close_session\n\nclass UserRepository:\n    @staticmethod\n    def get_user(email):\n        \"\"\"Get a user by email, creating one if it doesn't exist\"\"\"\n        session = get_session()\n        try:\n            user = session.query(User).filter(User.email == email).first()\n            if not user:\n                user = User(email=email)\n                stats = Stats(user=user)\n                session.add(user)\n                session.add(stats)\n                session.commit()\n            return user\n        except SQLAlchemyError as e:\n            session.rollback()\n            raise e\n        finally:\n            close_session(session)\n    \n    @staticmethod\n    def save_user(user):\n        \"\"\"Save changes to a user\"\"\"\n        session = get_session()\n        try:\n            session.add(user)\n            session.commit()\n        except SQLAlchemyError as e:\n            session.rollback()\n            raise e\n        finally:\n            close_session(session)\n    \n    @staticmethod\n    def get_user_with_stats(email):\n        \"\"\"Get a user with stats eagerly loaded\"\"\"\n        session = get_session()\n        try:\n            user = session.query(User).filter(User.email == email).first()\n            if not user:\n                user = User(email=email)\n                stats = Stats(user=user)\n                session.add(user)\n                session.add(stats)\n                session.commit()\n            # Ensure stats is loaded\n            if not user.stats:\n                stats = Stats(user=user)\n                session.add(stats)\n                session.commit()\n            return user\n        except SQLAlchemyError as e:\n            session.rollback()\n            raise e\n        finally:\n            close_session(session)\n    \n    @staticmethod\n    def delete_user(email):\n        \"\"\"Delete a user by email\"\"\"\n        session = get_session()\n        try:\n            user = session.query(User).filter(User.email == email).first()\n            if user:\n                session.delete(user)\n                session.commit()\n                return True\n            return False\n        except SQLAlchemyError as e:\n            session.rollback()\n            raise e\n        finally:\n            close_session(session)\n```\n\nThis implementation follows these best practices:\n1. Session management with proper opening and closing\n2. Transaction handling with commit and rollback\n3. Error handling for database exceptions\n4. Automatic user and stats creation if they don't exist\n5. Method to eagerly load stats with user to avoid N+1 query problems",
        "testStrategy": "1. Unit tests:\n   - Test get_user creates a new user when one doesn't exist\n   - Test get_user returns existing user when one exists\n   - Test save_user persists changes\n   - Test get_user_with_stats loads stats relationship\n   - Test delete_user removes a user\n\n2. Integration tests:\n   - Test with actual database to verify persistence\n   - Test transaction rollback on error\n   - Test concurrent access to same user\n\n3. Error handling tests:\n   - Test behavior when database is unavailable\n   - Test with invalid data to ensure proper error handling",
        "priority": "high",
        "dependencies": [
          27
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 29,
        "title": "Implement Stats Repository",
        "description": "Create a repository for managing user statistics data, including methods to update and retrieve stats.",
        "details": "Create a stats_repository.py file with the following implementation:\n\n```python\nfrom sqlalchemy.exc import SQLAlchemyError\nfrom models import User, Stats\nfrom db_config import get_session, close_session\nfrom user_repository import UserRepository\n\nclass StatsRepository:\n    @staticmethod\n    def get_stats(user_email):\n        \"\"\"Get stats for a user, creating if necessary\"\"\"\n        session = get_session()\n        try:\n            # Get user with stats\n            user = UserRepository.get_user_with_stats(user_email)\n            return user.stats\n        except SQLAlchemyError as e:\n            session.rollback()\n            raise e\n        finally:\n            close_session(session)\n    \n    @staticmethod\n    def update_stats(user_email, **kwargs):\n        \"\"\"Update user stats with provided values\"\"\"\n        session = get_session()\n        try:\n            # Get user with stats\n            user = UserRepository.get_user_with_stats(user_email)\n            stats = user.stats\n            \n            # Update stats fields\n            for key, value in kwargs.items():\n                if hasattr(stats, key):\n                    if key == 'domains_unsubscribed' and isinstance(value, dict):\n                        # Merge dictionaries for domains_unsubscribed\n                        current_domains = stats.domains_unsubscribed or {}\n                        for domain, count in value.items():\n                            current_domains[domain] = current_domains.get(domain, 0) + count\n                        setattr(stats, key, current_domains)\n                    else:\n                        # For numeric fields, add the new value\n                        if key in ['total_scanned', 'total_unsubscribed', 'time_saved']:\n                            current_value = getattr(stats, key) or 0\n                            setattr(stats, key, current_value + value)\n                        else:\n                            # For other fields, replace the value\n                            setattr(stats, key, value)\n            \n            session.add(stats)\n            session.commit()\n            return stats\n        except SQLAlchemyError as e:\n            session.rollback()\n            raise e\n        finally:\n            close_session(session)\n    \n    @staticmethod\n    def increment_scanned(user_email, count=1):\n        \"\"\"Increment the total_scanned count\"\"\"\n        return StatsRepository.update_stats(user_email, total_scanned=count)\n    \n    @staticmethod\n    def increment_unsubscribed(user_email, count=1, domain=None, time_saved=0):\n        \"\"\"Increment the total_unsubscribed count and update related stats\"\"\"\n        domains_update = {}\n        if domain:\n            domains_update[domain] = count\n        \n        return StatsRepository.update_stats(\n            user_email, \n            total_unsubscribed=count,\n            domains_unsubscribed=domains_update,\n            time_saved=time_saved\n        )\n```\n\nThis implementation provides:\n1. Methods to get and update user stats\n2. Special handling for domains_unsubscribed as a JSON field\n3. Convenience methods for common operations (increment_scanned, increment_unsubscribed)\n4. Proper transaction and session management\n5. Error handling for database operations",
        "testStrategy": "1. Unit tests:\n   - Test get_stats returns stats for existing user\n   - Test update_stats with various field combinations\n   - Test increment_scanned increases total_scanned count\n   - Test increment_unsubscribed updates multiple fields correctly\n   - Test domains_unsubscribed merging logic\n\n2. Integration tests:\n   - Test persistence of stats updates\n   - Test concurrent updates to same stats object\n   - Test with large domain dictionaries\n\n3. Edge case tests:\n   - Test with invalid field names\n   - Test with null or invalid values\n   - Test with very large numeric values",
        "priority": "high",
        "dependencies": [
          28
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 30,
        "title": "Implement Activity Repository",
        "description": "Create a repository for managing user activity data, including methods to record and retrieve activities.",
        "details": "Create an activity_repository.py file with the following implementation:\n\n```python\nfrom sqlalchemy.exc import SQLAlchemyError\nfrom sqlalchemy import desc\nfrom models import User, Activity\nfrom db_config import get_session, close_session\nfrom user_repository import UserRepository\nfrom datetime import datetime\n\nclass ActivityRepository:\n    @staticmethod\n    def add_activity(user_email, activity_type, metadata=None):\n        \"\"\"Add a new activity for a user\"\"\"\n        if metadata is None:\n            metadata = {}\n            \n        session = get_session()\n        try:\n            # Ensure user exists\n            user = UserRepository.get_user(user_email)\n            \n            # Create activity\n            activity = Activity(\n                user_email=user_email,\n                activity_type=activity_type,\n                timestamp=datetime.utcnow(),\n                metadata=metadata\n            )\n            \n            session.add(activity)\n            session.commit()\n            return activity\n        except SQLAlchemyError as e:\n            session.rollback()\n            raise e\n        finally:\n            close_session(session)\n    \n    @staticmethod\n    def get_activities(user_email, limit=100, activity_type=None):\n        \"\"\"Get activities for a user with optional filtering and limit\"\"\"\n        session = get_session()\n        try:\n            query = session.query(Activity).filter(Activity.user_email == user_email)\n            \n            if activity_type:\n                query = query.filter(Activity.activity_type == activity_type)\n                \n            activities = query.order_by(desc(Activity.timestamp)).limit(limit).all()\n            return activities\n        except SQLAlchemyError as e:\n            session.rollback()\n            raise e\n        finally:\n            close_session(session)\n    \n    @staticmethod\n    def get_activity_count(user_email, activity_type=None):\n        \"\"\"Get count of activities for a user with optional filtering\"\"\"\n        session = get_session()\n        try:\n            query = session.query(Activity).filter(Activity.user_email == user_email)\n            \n            if activity_type:\n                query = query.filter(Activity.activity_type == activity_type)\n                \n            count = query.count()\n            return count\n        except SQLAlchemyError as e:\n            session.rollback()\n            raise e\n        finally:\n            close_session(session)\n    \n    @staticmethod\n    def clear_activities(user_email, activity_type=None):\n        \"\"\"Clear activities for a user with optional filtering\"\"\"\n        session = get_session()\n        try:\n            query = session.query(Activity).filter(Activity.user_email == user_email)\n            \n            if activity_type:\n                query = query.filter(Activity.activity_type == activity_type)\n                \n            deleted_count = query.delete(synchronize_session=False)\n            session.commit()\n            return deleted_count\n        except SQLAlchemyError as e:\n            session.rollback()\n            raise e\n        finally:\n            close_session(session)\n```\n\nThis implementation provides:\n1. Method to add new activities with metadata\n2. Method to retrieve activities with filtering and pagination\n3. Method to count activities\n4. Method to clear activities\n5. Proper ordering of activities (newest first)\n6. Proper transaction and session management\n7. Error handling for database operations",
        "testStrategy": "1. Unit tests:\n   - Test add_activity creates a new activity\n   - Test get_activities returns activities in correct order\n   - Test filtering by activity_type\n   - Test limit parameter works correctly\n   - Test get_activity_count returns correct count\n   - Test clear_activities removes activities\n\n2. Integration tests:\n   - Test persistence of activities\n   - Test with various metadata structures\n   - Test with large number of activities\n\n3. Edge case tests:\n   - Test with empty metadata\n   - Test with very large metadata\n   - Test with special characters in activity_type",
        "priority": "high",
        "dependencies": [
          28
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 31,
        "title": "Migrate User Stats Logic to Database",
        "description": "Update the existing user stats management code to use the database repositories instead of in-memory storage.",
        "details": "Identify the current in-memory user stats implementation and update it to use the new database repositories. Here's a general approach:\n\n1. Locate the current user stats implementation (likely in a file like user_manager.py or stats_manager.py)\n\n2. Replace in-memory storage with database calls:\n\n```python\n# Before (example of in-memory implementation)\nclass UserManager:\n    def __init__(self):\n        self.user_stats = {}  # In-memory storage\n    \n    def get_user_stats(self, email):\n        if email not in self.user_stats:\n            self.user_stats[email] = {\n                'total_scanned': 0,\n                'total_unsubscribed': 0,\n                'time_saved': 0,\n                'domains_unsubscribed': {}\n            }\n        return self.user_stats[email]\n    \n    def update_scanned(self, email, count=1):\n        stats = self.get_user_stats(email)\n        stats['total_scanned'] += count\n        return stats\n    \n    def update_unsubscribed(self, email, domain, time_saved=1):\n        stats = self.get_user_stats(email)\n        stats['total_unsubscribed'] += 1\n        stats['time_saved'] += time_saved\n        \n        if domain not in stats['domains_unsubscribed']:\n            stats['domains_unsubscribed'][domain] = 0\n        stats['domains_unsubscribed'][domain] += 1\n        \n        return stats\n\n# After (using database repositories)\nfrom stats_repository import StatsRepository\n\nclass UserManager:\n    def get_user_stats(self, email):\n        # Get stats from database\n        stats = StatsRepository.get_stats(email)\n        \n        # Convert to dictionary format for backward compatibility\n        return {\n            'total_scanned': stats.total_scanned or 0,\n            'total_unsubscribed': stats.total_unsubscribed or 0,\n            'time_saved': stats.time_saved or 0,\n            'domains_unsubscribed': stats.domains_unsubscribed or {}\n        }\n    \n    def update_scanned(self, email, count=1):\n        # Update in database\n        stats = StatsRepository.increment_scanned(email, count)\n        \n        # Return in dictionary format for backward compatibility\n        return {\n            'total_scanned': stats.total_scanned or 0,\n            'total_unsubscribed': stats.total_unsubscribed or 0,\n            'time_saved': stats.time_saved or 0,\n            'domains_unsubscribed': stats.domains_unsubscribed or {}\n        }\n    \n    def update_unsubscribed(self, email, domain, time_saved=1):\n        # Update in database\n        stats = StatsRepository.increment_unsubscribed(\n            email, count=1, domain=domain, time_saved=time_saved\n        )\n        \n        # Return in dictionary format for backward compatibility\n        return {\n            'total_scanned': stats.total_scanned or 0,\n            'total_unsubscribed': stats.total_unsubscribed or 0,\n            'time_saved': stats.time_saved or 0,\n            'domains_unsubscribed': stats.domains_unsubscribed or {}\n        }\n```\n\n3. Ensure backward compatibility by maintaining the same return formats\n\n4. Add error handling for database operations:\n\n```python\nfrom sqlalchemy.exc import SQLAlchemyError\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass UserManager:\n    # ... other methods ...\n    \n    def update_scanned(self, email, count=1):\n        try:\n            stats = StatsRepository.increment_scanned(email, count)\n            # Return in dictionary format for backward compatibility\n            return {\n                'total_scanned': stats.total_scanned or 0,\n                'total_unsubscribed': stats.total_unsubscribed or 0,\n                'time_saved': stats.time_saved or 0,\n                'domains_unsubscribed': stats.domains_unsubscribed or {}\n            }\n        except SQLAlchemyError as e:\n            logger.error(f\"Database error updating scanned count: {e}\")\n            # Fallback to in-memory behavior for resilience\n            return {\n                'total_scanned': count,\n                'total_unsubscribed': 0,\n                'time_saved': 0,\n                'domains_unsubscribed': {}\n            }\n```\n\n5. Consider adding a data migration function to move existing in-memory data to the database during startup:\n\n```python\ndef migrate_in_memory_stats_to_db(in_memory_stats):\n    \"\"\"Migrate in-memory stats to database\"\"\"\n    for email, stats in in_memory_stats.items():\n        try:\n            StatsRepository.update_stats(\n                email,\n                total_scanned=stats.get('total_scanned', 0),\n                total_unsubscribed=stats.get('total_unsubscribed', 0),\n                time_saved=stats.get('time_saved', 0),\n                domains_unsubscribed=stats.get('domains_unsubscribed', {})\n            )\n        except SQLAlchemyError as e:\n            logger.error(f\"Error migrating stats for {email}: {e}\")\n```",
        "testStrategy": "1. Unit tests:\n   - Test that the updated methods call the repository methods\n   - Test that the return format matches the original format\n   - Test error handling behavior\n\n2. Integration tests:\n   - Test end-to-end flow from API to database\n   - Verify data is persisted correctly\n   - Test migration of existing data\n\n3. Backward compatibility tests:\n   - Test that existing code using the UserManager continues to work\n   - Test that the return values match expected format\n\n4. Performance tests:\n   - Compare performance of database vs in-memory implementation\n   - Test with large datasets",
        "priority": "medium",
        "dependencies": [
          29
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 32,
        "title": "Migrate User Activities Logic to Database",
        "description": "Update the existing user activities management code to use the database repositories instead of in-memory storage.",
        "details": "Identify the current in-memory user activities implementation and update it to use the new database repositories. Here's a general approach:\n\n1. Locate the current user activities implementation (likely in a file like activity_manager.py or user_manager.py)\n\n2. Replace in-memory storage with database calls:\n\n```python\n# Before (example of in-memory implementation)\nclass ActivityManager:\n    def __init__(self):\n        self.user_activities = {}  # In-memory storage\n    \n    def add_activity(self, email, activity_type, metadata=None):\n        if email not in self.user_activities:\n            self.user_activities[email] = []\n        \n        activity = {\n            'type': activity_type,\n            'timestamp': datetime.utcnow().isoformat(),\n            'metadata': metadata or {}\n        }\n        \n        self.user_activities[email].append(activity)\n        return activity\n    \n    def get_activities(self, email, limit=100):\n        if email not in self.user_activities:\n            return []\n        \n        activities = self.user_activities[email]\n        # Sort by timestamp (newest first)\n        sorted_activities = sorted(activities, key=lambda x: x['timestamp'], reverse=True)\n        \n        return sorted_activities[:limit]\n\n# After (using database repositories)\nfrom activity_repository import ActivityRepository\nfrom datetime import datetime\n\nclass ActivityManager:\n    def add_activity(self, email, activity_type, metadata=None):\n        # Add activity to database\n        activity = ActivityRepository.add_activity(email, activity_type, metadata)\n        \n        # Return in dictionary format for backward compatibility\n        return {\n            'type': activity.activity_type,\n            'timestamp': activity.timestamp.isoformat(),\n            'metadata': activity.metadata or {}\n        }\n    \n    def get_activities(self, email, limit=100):\n        # Get activities from database\n        activities = ActivityRepository.get_activities(email, limit=limit)\n        \n        # Convert to dictionary format for backward compatibility\n        return [\n            {\n                'type': activity.activity_type,\n                'timestamp': activity.timestamp.isoformat(),\n                'metadata': activity.metadata or {}\n            }\n            for activity in activities\n        ]\n```\n\n3. Ensure backward compatibility by maintaining the same return formats\n\n4. Add error handling for database operations:\n\n```python\nfrom sqlalchemy.exc import SQLAlchemyError\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass ActivityManager:\n    # ... other methods ...\n    \n    def add_activity(self, email, activity_type, metadata=None):\n        try:\n            activity = ActivityRepository.add_activity(email, activity_type, metadata)\n            \n            # Return in dictionary format for backward compatibility\n            return {\n                'type': activity.activity_type,\n                'timestamp': activity.timestamp.isoformat(),\n                'metadata': activity.metadata or {}\n            }\n        except SQLAlchemyError as e:\n            logger.error(f\"Database error adding activity: {e}\")\n            # Fallback to in-memory behavior for resilience\n            return {\n                'type': activity_type,\n                'timestamp': datetime.utcnow().isoformat(),\n                'metadata': metadata or {}\n            }\n```\n\n5. Consider adding a data migration function to move existing in-memory activities to the database during startup:\n\n```python\ndef migrate_in_memory_activities_to_db(in_memory_activities):\n    \"\"\"Migrate in-memory activities to database\"\"\"\n    for email, activities in in_memory_activities.items():\n        for activity in activities:\n            try:\n                ActivityRepository.add_activity(\n                    email,\n                    activity.get('type', 'unknown'),\n                    metadata=activity.get('metadata', {})\n                )\n            except SQLAlchemyError as e:\n                logger.error(f\"Error migrating activity for {email}: {e}\")\n```",
        "testStrategy": "1. Unit tests:\n   - Test that the updated methods call the repository methods\n   - Test that the return format matches the original format\n   - Test error handling behavior\n\n2. Integration tests:\n   - Test end-to-end flow from API to database\n   - Verify activities are persisted correctly\n   - Test migration of existing activities\n\n3. Backward compatibility tests:\n   - Test that existing code using the ActivityManager continues to work\n   - Test that the return values match expected format\n\n4. Performance tests:\n   - Compare performance of database vs in-memory implementation\n   - Test with large numbers of activities",
        "priority": "medium",
        "dependencies": [
          30
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 33,
        "title": "Implement Database Connection Error Handling",
        "description": "Add robust error handling for database connection issues to ensure the application remains functional even when the database is temporarily unavailable.",
        "details": "Implement a resilient database access pattern with fallback mechanisms:\n\n1. Create a db_utils.py file with retry logic and connection monitoring:\n\n```python\nimport time\nimport logging\nfrom functools import wraps\nfrom sqlalchemy.exc import SQLAlchemyError, OperationalError, DisconnectionError\nfrom db_config import get_session, close_session\n\nlogger = logging.getLogger(__name__)\n\n# In-memory fallback storage\nfallback_storage = {\n    'users': {},\n    'stats': {},\n    'activities': {}\n}\n\ndef with_db_retry(max_retries=3, retry_delay=0.5):\n    \"\"\"Decorator to retry database operations on connection errors\"\"\"\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            retries = 0\n            while retries < max_retries:\n                try:\n                    return func(*args, **kwargs)\n                except (OperationalError, DisconnectionError) as e:\n                    retries += 1\n                    if retries >= max_retries:\n                        logger.error(f\"Database connection failed after {max_retries} attempts: {e}\")\n                        raise\n                    logger.warning(f\"Database connection error, retrying ({retries}/{max_retries}): {e}\")\n                    time.sleep(retry_delay * retries)  # Exponential backoff\n        return wrapper\n    return decorator\n\nclass DatabaseHealthCheck:\n    _is_healthy = True\n    _last_check = 0\n    _check_interval = 60  # seconds\n    \n    @classmethod\n    def is_healthy(cls):\n        \"\"\"Check if database is healthy, with caching to avoid too frequent checks\"\"\"\n        current_time = time.time()\n        if current_time - cls._last_check > cls._check_interval:\n            cls._check_health()\n            cls._last_check = current_time\n        return cls._is_healthy\n    \n    @classmethod\n    def _check_health(cls):\n        \"\"\"Perform actual health check\"\"\"\n        session = get_session()\n        try:\n            # Simple query to check database connection\n            session.execute(\"SELECT 1\")\n            cls._is_healthy = True\n        except SQLAlchemyError as e:\n            logger.error(f\"Database health check failed: {e}\")\n            cls._is_healthy = False\n        finally:\n            close_session(session)\n    \n    @classmethod\n    def set_unhealthy(cls):\n        \"\"\"Mark database as unhealthy (called when operations fail)\"\"\"\n        cls._is_healthy = False\n        cls._last_check = time.time()\n\ndef fallback_to_memory(email_param_name='user_email'):\n    \"\"\"Decorator to fallback to in-memory storage when database is unavailable\"\"\"\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            if DatabaseHealthCheck.is_healthy():\n                try:\n                    return func(*args, **kwargs)\n                except SQLAlchemyError as e:\n                    logger.error(f\"Database error in {func.__name__}: {e}\")\n                    DatabaseHealthCheck.set_unhealthy()\n                    # Fall through to in-memory fallback\n            \n            # Fallback to in-memory storage\n            logger.warning(f\"Using in-memory fallback for {func.__name__}\")\n            \n            # Extract email from args or kwargs based on the function signature\n            email = kwargs.get(email_param_name)\n            if email is None and args and len(args) > 0:\n                # Assume first arg is the repository instance, second is email\n                if len(args) > 1:\n                    email = args[1]\n            \n            # Implement fallback logic based on function name\n            if 'get_stats' in func.__name__:\n                return fallback_storage['stats'].get(email, {'total_scanned': 0, 'total_unsubscribed': 0, 'time_saved': 0, 'domains_unsubscribed': {}})\n            elif 'update_stats' in func.__name__:\n                stats = fallback_storage['stats'].get(email, {'total_scanned': 0, 'total_unsubscribed': 0, 'time_saved': 0, 'domains_unsubscribed': {}})\n                for key, value in kwargs.items():\n                    if key != email_param_name:\n                        stats[key] = value\n                fallback_storage['stats'][email] = stats\n                return stats\n            elif 'add_activity' in func.__name__:\n                activity_type = kwargs.get('activity_type')\n                metadata = kwargs.get('metadata', {})\n                activity = {'type': activity_type, 'timestamp': time.time(), 'metadata': metadata}\n                if email not in fallback_storage['activities']:\n                    fallback_storage['activities'][email] = []\n                fallback_storage['activities'][email].append(activity)\n                return activity\n            elif 'get_activities' in func.__name__:\n                return fallback_storage['activities'].get(email, [])\n            \n            # Default fallback\n            return None\n        \n        return wrapper\n    return decorator\n```\n\n2. Update the repository classes to use these decorators:\n\n```python\nfrom db_utils import with_db_retry, fallback_to_memory\n\nclass StatsRepository:\n    @staticmethod\n    @with_db_retry(max_retries=3)\n    @fallback_to_memory(email_param_name='user_email')\n    def get_stats(user_email):\n        # Existing implementation\n        ...\n    \n    @staticmethod\n    @with_db_retry(max_retries=3)\n    @fallback_to_memory(email_param_name='user_email')\n    def update_stats(user_email, **kwargs):\n        # Existing implementation\n        ...\n\nclass ActivityRepository:\n    @staticmethod\n    @with_db_retry(max_retries=3)\n    @fallback_to_memory(email_param_name='user_email')\n    def add_activity(user_email, activity_type, metadata=None):\n        # Existing implementation\n        ...\n    \n    @staticmethod\n    @with_db_retry(max_retries=3)\n    @fallback_to_memory(email_param_name='user_email')\n    def get_activities(user_email, limit=100, activity_type=None):\n        # Existing implementation\n        ...\n```\n\n3. Add a background task to periodically sync in-memory data to database when it becomes available again:\n\n```python\nimport threading\nimport time\n\ndef sync_fallback_data_to_db():\n    \"\"\"Background task to sync in-memory fallback data to database when available\"\"\"\n    while True:\n        time.sleep(60)  # Check every minute\n        \n        if not DatabaseHealthCheck.is_healthy():\n            # Re-check database health\n            DatabaseHealthCheck._check_health()\n            if not DatabaseHealthCheck.is_healthy():\n                continue  # Still unhealthy, skip sync\n        \n        # Sync stats\n        for email, stats in fallback_storage['stats'].items():\n            try:\n                StatsRepository.update_stats(email, **stats)\n                # Clear from fallback storage after successful sync\n                del fallback_storage['stats'][email]\n            except SQLAlchemyError as e:\n                logger.error(f\"Failed to sync stats for {email}: {e}\")\n        \n        # Sync activities\n        for email, activities in fallback_storage['activities'].items():\n            for activity in activities:\n                try:\n                    ActivityRepository.add_activity(\n                        email,\n                        activity.get('type', 'unknown'),\n                        metadata=activity.get('metadata', {})\n                    )\n                except SQLAlchemyError as e:\n                    logger.error(f\"Failed to sync activity for {email}: {e}\")\n            # Clear from fallback storage after sync attempt\n            del fallback_storage['activities'][email]\n\n# Start background sync thread during application startup\ndef start_sync_thread():\n    sync_thread = threading.Thread(target=sync_fallback_data_to_db, daemon=True)\n    sync_thread.start()\n```",
        "testStrategy": "1. Unit tests:\n   - Test retry decorator with simulated database errors\n   - Test fallback decorator with simulated database unavailability\n   - Test DatabaseHealthCheck class functionality\n\n2. Integration tests:\n   - Test application behavior when database is unavailable\n   - Test fallback to in-memory storage\n   - Test recovery when database becomes available again\n   - Test background sync functionality\n\n3. Stress tests:\n   - Test with intermittent database connectivity\n   - Test with high load during database outage\n   - Test data integrity after recovery\n\n4. Mocking tests:\n   - Use mock database connections to simulate various error conditions\n   - Test different SQLAlchemy error types",
        "priority": "medium",
        "dependencies": [
          31,
          32
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 34,
        "title": "Implement Database Migration Script",
        "description": "Create a script to handle database schema migrations for future updates, ensuring smooth upgrades without data loss.",
        "details": "Implement a database migration system using Alembic, which integrates well with SQLAlchemy:\n\n1. Add Alembic to requirements.txt:\n```\nalembic==1.12.1\n```\n\n2. Initialize Alembic in the project:\n```bash\nalembic init migrations\n```\n\n3. Configure Alembic to work with the existing SQLAlchemy models by updating the `migrations/env.py` file:\n\n```python\n# Add these imports at the top\nimport os\nimport sys\nfrom dotenv import load_dotenv\n\n# Add project root to path so we can import our models\nsys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))\n\n# Load environment variables\nload_dotenv()\n\n# Import models and database configuration\nfrom models import Base\nfrom db_config import DATABASE_URL\n\n# Update target_metadata\ntarget_metadata = Base.metadata\n\n# Update the config section to use DATABASE_URL from environment\nconfig.set_main_option('sqlalchemy.url', DATABASE_URL)\n```\n\n4. Create an initial migration for the current schema:\n\n```bash\nalembic revision --autogenerate -m \"Initial schema\"\n```\n\n5. Create a migration script to handle future schema changes:\n\n```python\n# migrations/script.py.mako (template for migration scripts)\n\"\"\"\n${message}\n\nRevision ID: ${up_revision}\nRevises: ${down_revision | comma,n}\nCreate Date: ${create_date}\n\"\"\"\n\nfrom alembic import op\nimport sqlalchemy as sa\n${imports if imports else \"\"}\n\n# revision identifiers, used by Alembic\nrevision = ${repr(up_revision)}\ndown_revision = ${repr(down_revision)}\nbranch_labels = ${repr(branch_labels)}\ndepends_on = ${repr(depends_on)}\n\n\ndef upgrade():\n    ${upgrades if upgrades else \"pass\"}\n\n\ndef downgrade():\n    ${downgrades if downgrades else \"pass\"}\n```\n\n6. Create a migration utility script (db_migrate.py):\n\n```python\nimport os\nimport argparse\nfrom alembic.config import Config\nfrom alembic import command\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\ndef run_migrations(action, message=None, revision=None):\n    \"\"\"Run database migrations\"\"\"\n    # Get the directory of this script\n    dir_path = os.path.dirname(os.path.realpath(__file__))\n    \n    # Create Alembic configuration\n    alembic_cfg = Config(os.path.join(dir_path, 'alembic.ini'))\n    \n    # Set the path to the migration scripts\n    alembic_cfg.set_main_option('script_location', os.path.join(dir_path, 'migrations'))\n    \n    # Set the database URL\n    database_url = os.getenv('DATABASE_URL')\n    if database_url:\n        alembic_cfg.set_main_option('sqlalchemy.url', database_url)\n    \n    # Run the specified command\n    if action == 'upgrade':\n        command.upgrade(alembic_cfg, revision or 'head')\n    elif action == 'downgrade':\n        command.downgrade(alembic_cfg, revision or '-1')\n    elif action == 'current':\n        command.current(alembic_cfg)\n    elif action == 'history':\n        command.history(alembic_cfg)\n    elif action == 'revision':\n        if not message:\n            raise ValueError(\"Message is required for revision\")\n        command.revision(alembic_cfg, message=message, autogenerate=True)\n    else:\n        raise ValueError(f\"Unknown action: {action}\")\n\ndef main():\n    parser = argparse.ArgumentParser(description='Database migration utility')\n    parser.add_argument('action', choices=['upgrade', 'downgrade', 'current', 'history', 'revision'],\n                        help='Migration action to perform')\n    parser.add_argument('--message', '-m', help='Message for revision')\n    parser.add_argument('--revision', '-r', help='Revision identifier')\n    \n    args = parser.parse_args()\n    \n    run_migrations(args.action, args.message, args.revision)\n\nif __name__ == '__main__':\n    main()\n```\n\n7. Add a function to initialize the database and run migrations during application startup:\n\n```python\ndef init_database():\n    \"\"\"Initialize database and run migrations\"\"\"\n    from db_config import init_db\n    from db_migrate import run_migrations\n    \n    # Initialize database (create tables if they don't exist)\n    init_db()\n    \n    # Run any pending migrations\n    try:\n        run_migrations('upgrade')\n    except Exception as e:\n        logger.error(f\"Error running migrations: {e}\")\n        # Continue anyway, as tables should exist from init_db\n```\n\n8. Update the application startup code to call init_database():\n\n```python\n# In your main application file\nfrom database import init_database\n\n# During application startup\ninit_database()\n```",
        "testStrategy": "1. Unit tests:\n   - Test migration script with mock Alembic commands\n   - Test command-line argument parsing\n\n2. Integration tests:\n   - Test creating a new migration\n   - Test upgrading the database\n   - Test downgrading the database\n   - Test with an empty database\n   - Test with an existing database\n\n3. Schema change tests:\n   - Create a test migration that adds a new column\n   - Create a test migration that modifies a column\n   - Create a test migration that adds a new table\n   - Verify data integrity after migrations\n\n4. Error handling tests:\n   - Test with invalid migration commands\n   - Test with invalid database URL\n   - Test recovery from failed migrations",
        "priority": "medium",
        "dependencies": [
          26,
          27
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 35,
        "title": "Create Comprehensive Integration Tests",
        "description": "Develop a suite of integration tests to verify the complete database persistence functionality, ensuring all components work together correctly.",
        "details": "Create a comprehensive test suite to verify the database persistence functionality:\n\n1. Set up a test configuration file (test_config.py):\n\n```python\nimport os\nimport pytest\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker, scoped_session\nfrom models import Base, User, Stats, Activity\n\n# Test database URL - use in-memory SQLite for tests\nTEST_DATABASE_URL = 'sqlite:///:memory:'\n\n@pytest.fixture(scope='function')\ndef test_engine():\n    \"\"\"Create a test database engine\"\"\"\n    engine = create_engine(TEST_DATABASE_URL)\n    yield engine\n    engine.dispose()\n\n@pytest.fixture(scope='function')\ndef test_session_factory(test_engine):\n    \"\"\"Create a test session factory\"\"\"\n    Base.metadata.create_all(test_engine)\n    session_factory = sessionmaker(bind=test_engine)\n    yield session_factory\n    Base.metadata.drop_all(test_engine)\n\n@pytest.fixture(scope='function')\ndef test_session(test_session_factory):\n    \"\"\"Create a test session\"\"\"\n    session = test_session_factory()\n    yield session\n    session.close()\n\n@pytest.fixture(scope='function')\ndef setup_test_db(monkeypatch, test_engine, test_session_factory):\n    \"\"\"Set up test database and patch the application to use it\"\"\"\n    # Create all tables\n    Base.metadata.create_all(test_engine)\n    \n    # Create scoped session\n    test_scoped_session = scoped_session(test_session_factory)\n    \n    # Patch the application's database session\n    from db_config import Session, get_session, close_session, engine\n    \n    # Store original values to restore later\n    original_session = Session\n    original_engine = engine\n    \n    # Patch with test versions\n    monkeypatch.setattr('db_config.Session', test_scoped_session)\n    monkeypatch.setattr('db_config.engine', test_engine)\n    \n    # Patch get_session and close_session functions\n    def patched_get_session():\n        return test_scoped_session()\n    \n    def patched_close_session(session):\n        session.close()\n    \n    monkeypatch.setattr('db_config.get_session', patched_get_session)\n    monkeypatch.setattr('db_config.close_session', patched_close_session)\n    \n    yield\n    \n    # Clean up\n    test_scoped_session.remove()\n    Base.metadata.drop_all(test_engine)\n    \n    # Restore original values\n    monkeypatch.setattr('db_config.Session', original_session)\n    monkeypatch.setattr('db_config.engine', original_engine)\n    monkeypatch.setattr('db_config.get_session', get_session)\n    monkeypatch.setattr('db_config.close_session', close_session)\n\n@pytest.fixture\ndef sample_user(test_session):\n    \"\"\"Create a sample user for testing\"\"\"\n    user = User(email='test@example.com')\n    stats = Stats(user=user, total_scanned=10, total_unsubscribed=5, time_saved=15.5, domains_unsubscribed={'example.com': 3, 'test.com': 2})\n    test_session.add(user)\n    test_session.add(stats)\n    test_session.commit()\n    return user\n\n@pytest.fixture\ndef sample_activities(test_session, sample_user):\n    \"\"\"Create sample activities for testing\"\"\"\n    activities = [\n        Activity(user_email=sample_user.email, activity_type='scan', metadata={'count': 10}),\n        Activity(user_email=sample_user.email, activity_type='unsubscribe', metadata={'domain': 'example.com'}),\n        Activity(user_email=sample_user.email, activity_type='unsubscribe', metadata={'domain': 'test.com'})\n    ]\n    for activity in activities:\n        test_session.add(activity)\n    test_session.commit()\n    return activities\n```\n\n2. Create integration tests for user repository (test_user_repository.py):\n\n```python\nimport pytest\nfrom user_repository import UserRepository\nfrom models import User\n\ndef test_get_user_creates_new_user(setup_test_db):\n    # Test getting a non-existent user creates a new one\n    email = 'new@example.com'\n    user = UserRepository.get_user(email)\n    \n    assert user is not None\n    assert user.email == email\n    assert user.stats is not None\n\ndef test_get_user_returns_existing_user(setup_test_db, sample_user):\n    # Test getting an existing user\n    user = UserRepository.get_user(sample_user.email)\n    \n    assert user is not None\n    assert user.email == sample_user.email\n\ndef test_save_user(setup_test_db, sample_user):\n    # Test saving changes to a user\n    user = UserRepository.get_user(sample_user.email)\n    UserRepository.save_user(user)\n    \n    # Verify user was saved\n    retrieved_user = UserRepository.get_user(sample_user.email)\n    assert retrieved_user is not None\n    assert retrieved_user.email == sample_user.email\n\ndef test_delete_user(setup_test_db, sample_user):\n    # Test deleting a user\n    result = UserRepository.delete_user(sample_user.email)\n    \n    assert result is True\n    \n    # Verify user was deleted\n    session = get_session()\n    user = session.query(User).filter(User.email == sample_user.email).first()\n    close_session(session)\n    \n    assert user is None\n```\n\n3. Create integration tests for stats repository (test_stats_repository.py):\n\n```python\nimport pytest\nfrom stats_repository import StatsRepository\n\ndef test_get_stats(setup_test_db, sample_user):\n    # Test getting stats for a user\n    stats = StatsRepository.get_stats(sample_user.email)\n    \n    assert stats is not None\n    assert stats.total_scanned == 10\n    assert stats.total_unsubscribed == 5\n    assert stats.time_saved == 15.5\n    assert stats.domains_unsubscribed == {'example.com': 3, 'test.com': 2}\n\ndef test_update_stats(setup_test_db, sample_user):\n    # Test updating stats\n    stats = StatsRepository.update_stats(\n        sample_user.email,\n        total_scanned=5,\n        total_unsubscribed=2,\n        time_saved=7.5,\n        domains_unsubscribed={'new.com': 1}\n    )\n    \n    assert stats is not None\n    assert stats.total_scanned == 15  # 10 + 5\n    assert stats.total_unsubscribed == 7  # 5 + 2\n    assert stats.time_saved == 23.0  # 15.5 + 7.5\n    assert stats.domains_unsubscribed == {'example.com': 3, 'test.com': 2, 'new.com': 1}\n\ndef test_increment_scanned(setup_test_db, sample_user):\n    # Test incrementing scanned count\n    stats = StatsRepository.increment_scanned(sample_user.email, 3)\n    \n    assert stats is not None\n    assert stats.total_scanned == 13  # 10 + 3\n\ndef test_increment_unsubscribed(setup_test_db, sample_user):\n    # Test incrementing unsubscribed count\n    stats = StatsRepository.increment_unsubscribed(\n        sample_user.email,\n        count=1,\n        domain='new.com',\n        time_saved=2.5\n    )\n    \n    assert stats is not None\n    assert stats.total_unsubscribed == 6  # 5 + 1\n    assert stats.time_saved == 18.0  # 15.5 + 2.5\n    assert stats.domains_unsubscribed['new.com'] == 1\n```\n\n4. Create integration tests for activity repository (test_activity_repository.py):\n\n```python\nimport pytest\nfrom activity_repository import ActivityRepository\n\ndef test_add_activity(setup_test_db, sample_user):\n    # Test adding an activity\n    activity = ActivityRepository.add_activity(\n        sample_user.email,\n        'test',\n        metadata={'test': 'data'}\n    )\n    \n    assert activity is not None\n    assert activity.user_email == sample_user.email\n    assert activity.activity_type == 'test'\n    assert activity.metadata == {'test': 'data'}\n\ndef test_get_activities(setup_test_db, sample_user, sample_activities):\n    # Test getting activities\n    activities = ActivityRepository.get_activities(sample_user.email)\n    \n    assert activities is not None\n    assert len(activities) == 3\n    assert activities[0].activity_type in ['scan', 'unsubscribe']\n\ndef test_get_activities_with_filter(setup_test_db, sample_user, sample_activities):\n    # Test getting activities with filter\n    activities = ActivityRepository.get_activities(sample_user.email, activity_type='unsubscribe')\n    \n    assert activities is not None\n    assert len(activities) == 2\n    assert all(a.activity_type == 'unsubscribe' for a in activities)\n\ndef test_get_activity_count(setup_test_db, sample_user, sample_activities):\n    # Test getting activity count\n    count = ActivityRepository.get_activity_count(sample_user.email)\n    \n    assert count == 3\n    \n    # Test with filter\n    count = ActivityRepository.get_activity_count(sample_user.email, activity_type='scan')\n    \n    assert count == 1\n\ndef test_clear_activities(setup_test_db, sample_user, sample_activities):\n    # Test clearing activities\n    deleted = ActivityRepository.clear_activities(sample_user.email, activity_type='scan')\n    \n    assert deleted == 1\n    \n    # Verify only scan activities were deleted\n    activities = ActivityRepository.get_activities(sample_user.email)\n    assert len(activities) == 2\n    assert all(a.activity_type == 'unsubscribe' for a in activities)\n```\n\n5. Create end-to-end integration tests (test_integration.py):\n\n```python\nimport pytest\nfrom user_repository import UserRepository\nfrom stats_repository import StatsRepository\nfrom activity_repository import ActivityRepository\n\ndef test_full_user_flow(setup_test_db):\n    \"\"\"Test the full user flow from creation to deletion\"\"\"\n    email = 'integration@example.com'\n    \n    # Create user\n    user = UserRepository.get_user(email)\n    assert user is not None\n    assert user.email == email\n    \n    # Update stats\n    stats = StatsRepository.update_stats(\n        email,\n        total_scanned=10,\n        total_unsubscribed=5,\n        time_saved=15.0,\n        domains_unsubscribed={'example.com': 3, 'test.com': 2}\n    )\n    assert stats is not None\n    assert stats.total_scanned == 10\n    \n    # Add activities\n    for i in range(5):\n        activity = ActivityRepository.add_activity(\n            email,\n            'test',\n            metadata={'index': i}\n        )\n        assert activity is not None\n    \n    # Get activities\n    activities = ActivityRepository.get_activities(email)\n    assert len(activities) == 5\n    \n    # Delete user\n    result = UserRepository.delete_user(email)\n    assert result is True\n    \n    # Verify cascade delete\n    stats = StatsRepository.get_stats(email)\n    assert stats is not None  # Should create new stats\n    assert stats.total_scanned == 0  # Should be default values\n    \n    activities = ActivityRepository.get_activities(email)\n    assert len(activities) == 0  # Should be empty\n\ndef test_concurrent_updates(setup_test_db):\n    \"\"\"Test concurrent updates to user stats\"\"\"\n    import threading\n    import time\n    \n    email = 'concurrent@example.com'\n    user = UserRepository.get_user(email)\n    \n    # Function to update stats in a thread\n    def update_stats(thread_id):\n        for i in range(10):\n            StatsRepository.increment_scanned(email, 1)\n            time.sleep(0.01)  # Small delay to increase chance of concurrency issues\n    \n    # Create and start threads\n    threads = []\n    for i in range(5):\n        thread = threading.Thread(target=update_stats, args=(i,))\n        threads.append(thread)\n        thread.start()\n    \n    # Wait for all threads to complete\n    for thread in threads:\n        thread.join()\n    \n    # Verify final stats\n    stats = StatsRepository.get_stats(email)\n    assert stats.total_scanned == 50  # 5 threads * 10 increments\n```",
        "testStrategy": "1. Run the integration tests in isolation:\n   - Use pytest to run each test file separately\n   - Verify each repository works correctly in isolation\n\n2. Run the full test suite:\n   - Use pytest to run all tests together\n   - Verify all components work together correctly\n\n3. Test with different database configurations:\n   - Test with SQLite in-memory database\n   - Test with actual PostgreSQL database (if available in CI/CD)\n\n4. Test error conditions:\n   - Test with database connection errors\n   - Test with invalid data\n   - Test with concurrent access\n\n5. Test performance:\n   - Measure query execution time\n   - Test with large datasets",
        "priority": "low",
        "dependencies": [
          28,
          29,
          30,
          33
        ],
        "status": "pending",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-07-12T19:27:05.186Z",
      "updated": "2025-07-13T19:22:54.481Z",
      "description": "Tasks for master context"
    }
  }
}